{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore GNF normalization methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Packages and presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from myImageLib import dirrec, bestcolor, bpass, wowcolor\n",
    "from skimage import io, measure\n",
    "import pandas as pd\n",
    "from scipy.signal import savgol_filter, medfilt\n",
    "import os\n",
    "import corrLib\n",
    "from numpy.polynomial.polynomial import polyvander\n",
    "from scipy.optimize import curve_fit\n",
    "from miscLib import label_slope\n",
    "from scipy import signal\n",
    "from scipy.interpolate import griddata\n",
    "import matplotlib\n",
    "import pandas as pd\n",
    "from scipy.ndimage import gaussian_filter1d, uniform_filter1d\n",
    "import typesetting.main as tm\n",
    "from corr_utils import *\n",
    "from IPython.display import clear_output\n",
    "from log import experiment_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------The log looks OK!--------\n"
     ]
    }
   ],
   "source": [
    "color_dict, marker_list = unified_symbols() # keep color and symbol consistent across different plot, for same concentrations\n",
    "data_master_dir = r'E:\\Google Drive' # data folder: Google drive for now, but may change in the future\n",
    "tm.prl('1-column-2-panel') # control the default plotting configurations, now I realize the parameters should vary from plot to plot\n",
    "dirs = data_log_mapping(kw='aug') # video info for GNF raw data, obtained from Aug 3rd to Aug 6th\n",
    "log_df = experiment_log()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Large scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_gnf(gnf_data, lb, xlim=None, sparse=3, normalize='1', volume_fraction=None ,mpp=0.33):\n",
    "    \"\"\"\n",
    "    Postprocess raw GNF data for plotting.\n",
    "    \n",
    "    Since we change the way of preparing GNF data, the corresponding function which is responsible for preparing ready-to-plot data needs to be modified. As far as I am concerned, the only function that needs to be changed is the `postprocess_gnf()`. To avoid issues, I want to keep the default behavior of the function, which rescale the starting point of all curves to 1. An additional keyword argument `normalize` will be added, and default to `'1'`, which standards for rescaling by the first point. Optionally, `normalize` can be set to `small-scale`, which applies the normalization described in Section 3.2. If `small-scale` is chosen, an additional keyword argument, `volume_fraction` will be required in order to calculate the rescaling factor. (implement after dinner)\n",
    "    \n",
    "    Args:\n",
    "    gnf_data -- DataFrame containing columns ('n', 'd'), generated by df2_nobp.py or df2_kinetics.py\n",
    "    lb -- size of bacteria (pixel, normalizing factor of x axis)\n",
    "    xlim -- box size beyond which the data get cut off (pixel), can be either integer or a list of 2 integers\n",
    "            if xlim is int, it is the upper limit, data above xlim will be cut off,\n",
    "            if xlim is a list, data outside [xlim[0], xlim[1]] will be cut off\n",
    "    sparse -- the degree to sparsify the data, 1 is doing nothing, 3 means only keep 1/3 of the orginal data\n",
    "    normalize -- the method to normalize the data. Choose from '1', None or 'small-scale'.\n",
    "                 '1': rescale y with y[0]\n",
    "                 'small-scale': rescale y with y[0] / \\sqrt{1 - volume_fraction}. Additional volume_fraction arg is required.\n",
    "                 None: no normalization will be applied.\n",
    "    Returns:\n",
    "    x, y -- a tuple that can be plotted directly using plt.plot(x, y)\n",
    "    \n",
    "    Edit:\n",
    "    12022020 -- Initial commit.\n",
    "    \n",
    "    Test:\n",
    "    # test new postprocess_gnf(gnf_data, lb, xlim=None, sparse=3, normalize='1', volume_fraction=None ,mpp=0.33)\n",
    "    data = pd.read_csv(r'E:\\moreData\\08032020\\df2_kinetics\\01\\kinetics_data.csv')\n",
    "    gnf_data = data.loc[data.segment==50]\n",
    "    lb = 10\n",
    "    # test normalize = '1'\n",
    "    x, y = postprocess_gnf(gnf_data, lb, xlim=[10, 10000], sparse=3, normalize='1')\n",
    "    plt.plot(x, y, label='1')\n",
    "    # test normalize = 'small-scale'\n",
    "    x, y = postprocess_gnf(gnf_data, lb, xlim=[1, 10000], sparse=3, normalize='small-scale', volume_fraction= 0.064)\n",
    "    plt.plot(x, y, label='small-scale')\n",
    "    # test normalize = '1'\n",
    "    x, y = postprocess_gnf(gnf_data, lb, xlim=[1, 10000], sparse=3, normalize=None)\n",
    "    plt.plot(x, y, label='None')\n",
    "    plt.loglog()\n",
    "    plt.legend(fontsize=5)\n",
    "    plt.xlabel('$l^2/l_b^2$')\n",
    "    plt.ylabel('$\\Delta N/\\sqrt N$')\n",
    "    \"\"\"    \n",
    "    \n",
    "    if xlim == None:\n",
    "        data = gnf_data\n",
    "    elif isinstance(xlim, int):\n",
    "        data = gnf_data.loc[gnf_data.n < xlim*lb**2]\n",
    "    elif isinstance(xlim, list) and len(xlim) == 2:\n",
    "        data = gnf_data.loc[(gnf_data.n>=xlim[0]*lb**2)&(gnf_data.n < xlim[1]*lb**2)]  \n",
    "    \n",
    "    if normalize == '1':\n",
    "        xx = data.n / lb**2\n",
    "        yy = data.d / data.n**0.5\n",
    "        yy = yy / yy.iat[0]\n",
    "    elif normalize == None:\n",
    "        xx = data.n / lb**2\n",
    "        yy = data.d / data.n**0.5\n",
    "    elif normalize == 'small-scale':\n",
    "        assert(volume_fraction is not None)\n",
    "        assert(volume_fraction < 1)\n",
    "        assert(xlim[0] <= 1) # make sure the first data point is at a smaller scale than lb\n",
    "        xx = data.n / lb**2\n",
    "        yy = data.d / data.n**0.5\n",
    "        yy = yy / yy.iat[0] * (1 - volume_fraction) ** 0.5        \n",
    "    else:\n",
    "        raise ValueError('Invalid normalize argument')\n",
    "    \n",
    "    # sparcify\n",
    "    x = xx[0:len(xx):sparse]\n",
    "    y = yy[0:len(xx):sparse]\n",
    "    \n",
    "    return x, y"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
