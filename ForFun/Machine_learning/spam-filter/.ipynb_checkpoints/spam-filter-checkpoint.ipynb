{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam filter\n",
    "\n",
    "Training data is from https://archive.ics.uci.edu/ml/datasets/spambase.\n",
    "\n",
    "Here, I implement a spam filter by naive-Bayes algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Read data\n",
    "\n",
    "**Data organization in file**\n",
    "\n",
    "The data is organized as a set of strings deliminated by commas. Each element denotes the frequency of certain word in an email. below is the first two lines of the data:\n",
    "```\n",
    "0,0.64,0.64,0,0.32,0,0,0,0,0,0,0.64,0,0,0,0.32,0,1.29,1.93,0,0.96,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.778,0,0,3.756,61,278,1\n",
    "0.21,0.28,0.5,0,0.14,0.28,0.21,0.07,0,0.94,0.21,0.79,0.65,0.21,0.14,0.14,0.07,0.28,3.47,0,1.59,0,0.43,0.43,0,0,0,0,0,0,0,0,0,0,0,0,0.07,0,0,0,0,0,0,0,0,0,0,0,0,0.132,0,0.372,0.18,0.048,5.114,101,1028,1\n",
    "...\n",
    "```\n",
    "The data has 4600 lines in total, each line consisting of 58 elements. The last element is either 0 (non-spam) or 1 (spam)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data in code**\n",
    "\n",
    "The data will be organized in two numpy arrays: data array and label array. Data array has a shape of (4601, 57), label array has a shape of (4601, 1). For the Naive-Bayes algorithm implementation, we will convert all the non-zero value in data array to 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "data_all = np.loadtxt('data\\spambase.data', delimiter=',')\n",
    "data_all[data_all > 0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Naive Bayes algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all = np.loadtxt('data\\spambase.data', delimiter=',')\n",
    "data = data_all[:, :57]\n",
    "label = data_all[:, -1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "inputs = tf.keras.Input(shape=(57, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.keras.layers.Dense(10, activation=tf.nn.relu)(inputs)\n",
    "x1 = tf.keras.layers.Dense(5, activation=tf.nn.relu)(x)\n",
    "x2 = tf.keras.layers.Dense(3, activation=tf.nn.relu)(x1)\n",
    "outputs = tf.keras.layers.Dense(1, activation=tf.sigmoid)(x2)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy()\n",
    "model.compile(optimizer='adam', loss=loss, metrics=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1323\n",
      "Epoch 2/5\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1310\n",
      "Epoch 3/5\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1296\n",
      "Epoch 4/5\n",
      "144/144 [==============================] - 0s 1ms/step - loss: 0.1328\n",
      "Epoch 5/5\n",
      "144/144 [==============================] - 0s 993us/step - loss: 0.1309\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x15986b116c8>"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=data, y=label, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "correct prediction\n"
     ]
    }
   ],
   "source": [
    "n = 3000\n",
    "pred = model.predict(data[n, :].reshape(1, 57))\n",
    "if int(pred*2) == label[n]:\n",
    "    print('correct prediction')\n",
    "else:\n",
    "    print('wrong prediction')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06911540969354488"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(data)\n",
    "det = np.floor(2*pred) - label\n",
    "np.count_nonzero(det) / len(det)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Daily summary 10242020**\n",
    "\n",
    "- The network training is now working. The structure of the network is still primitive and needs to be improved.\n",
    "- The use of data needs to be improved: divide data into train/dev/test sets.\n",
    "- Consider constructing an original dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
