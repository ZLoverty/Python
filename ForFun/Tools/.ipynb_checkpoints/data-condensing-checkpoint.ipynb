{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Condensing\n",
    "\n",
    "It is important to always keep data portable as an experimentalist. If we can easily take all the data needed for a manuscript with us (via a cloud storage solution like Google Drive), we can work anywhere at anytime as long as internet is available. More importantly, after publishing a paper with the data, it's much easier to share the data with other researchers, making the data more valuable. \n",
    "\n",
    "The nature of my current research, which relies strongly on large videos, makes it hard to keep all the data portable. However, the raw videos are never necessary. By analyzing the videos (such as PIV and PTV), we can get most essential data, which does not require a lot of storage space, and a cloud drive can easily afford some data like this kind. \n",
    "\n",
    "Currently, I save my data in a local hard drive. All the data are organized in folders in the following structure:\n",
    "\n",
    "- Date\n",
    "    - raw images (by number from 0 to total number of videos in the day)\n",
    "        - 01\n",
    "        - 02\n",
    "        - ...\n",
    "    - data from analysis\n",
    "        - piv_imseq (PIV)\n",
    "        - df2_kinetics (density fluctuations analysis - kinetics)\n",
    "        - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a good separation of raw data and data from analysis. Ideally, the data from analysis part should be the portable part. However, I find it not very feasible because the total size of analysis data is still large (for example the folder 08032020 has 14.3 GB analysis data at the time when I'm writing this document). I realize that when visualizing these data, not all data are used. For example, I don't need the flow field at every frame, but rather some frames for illustration. And other PIV flow fields may only be used for energy and flow order evolution, which abstract the detailed flow field in each frame into a single number.\n",
    "\n",
    "For important data, I always write a code to summarize the data of each day of experiment in \"summary.csv\". Here, I write a piece of code to copy all the \"summary.csv\" files to my Google Drive - research project folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Packages and presets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "from myImageLib import dirrec\n",
    "from corrLib import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Copy essential data files to a master folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_summary(src_folder, dest_folder, sub_folders, file_list=['summary.csv']):\n",
    "    \"\"\"\n",
    "    copy summary.csv files to other folder (mainly for cloud drive storage).\n",
    "    \n",
    "    Args:\n",
    "    src_folder -- source folder\n",
    "    dest_folder -- destination folder\n",
    "    sub_folders -- choose subfolders under source folder in which data are copied\n",
    "    \n",
    "    Returns:\n",
    "    None\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    for sf in sub_folders:\n",
    "        src = os.path.join(src_folder, sf)\n",
    "        for file in file_list:\n",
    "            f = dirrec(src, file)\n",
    "            for src_file in f:\n",
    "                dest_file = src_file.replace(src_folder, dest_folder)\n",
    "                dest = os.path.split(dest_file)[0]\n",
    "                if os.path.exists(dest) == False:\n",
    "                    os.makedirs(dest)\n",
    "        #             print('Create folder ' + dest)\n",
    "                shutil.copyfile(src_file, dest_file)\n",
    "                print('Copy file ' + dest_file.replace(dest_folder, ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copy file \\08032020\\cav_imseq\\cv-summary.csv\n",
      "Copy file \\08042020\\cav_imseq\\cv-summary.csv\n",
      "Copy file \\08052020\\cav_imseq\\cv-summary.csv\n",
      "Copy file \\08062020\\cav_imseq\\cv-summary.csv\n"
     ]
    }
   ],
   "source": [
    "# test copy_summary\n",
    "src_folder = r'E:\\moreData'\n",
    "dest_folder = r'E:\\Google Drive\\Research projects\\DF\\data\\level-2-data'\n",
    "sub_folders = ['08032020', '08042020', '08052020', '08062020']\n",
    "file_list = ['cv-summary.csv'] # 'summary.csv', 'kinetics_data.csv', 'intensity.csv', 'energy_order.csv'\n",
    "copy_summary(src_folder, dest_folder, sub_folders, file_list=file_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Slimming PIV data\n",
    "\n",
    "Currently, PIV data are saved as text files (.csv) with four columns (x, y, u, v). This structure requires at least twice of the space as needed. For example, a 42x50 grid PIV data file takes up 105 kb. As a result, 3600 frames of video can generate 180 mb data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(r'E:\\moreData\\test.npy', np.random.rand(7560, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 1,000,000 64-bit double precision floats forms a npy file of 7.62 mb, verifying that such a float is 64 bit, i.e. 8 bytes. A PIV dataset with 1800x42x50x2 = 7,560,000 floats is around 60 mb, 3 times smaller than the original text file (.csv).\n",
    "\n",
    "Although the size of PIV dataset can be significantly reduced in this way, making all the PIV data portable is still challenging. If I have 100 videos, the PIV data will be 6 gb, unfeasible for current downloading speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert text files to binary files, the first task is to strictly structure the data. For PIV data, besides velocity information, I need to store coordinate information (x, y). Other parameters, such as window size and fps, can be put in log files. Below I store x and y as a (2, m, n) array, where m and n are the number of rows and cols in the PIV data.\n",
    "\n",
    "I will first convert 08032020\\00 data to npy and save in folder \"piv_slim\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save frame 0000-0100\n",
      "Save frame 0100-0200\n",
      "Save frame 0200-0300\n",
      "Save frame 0300-0400\n",
      "Save frame 0400-0500\n",
      "Save frame 0500-0600\n",
      "Save frame 0600-0700\n",
      "Save frame 0700-0800\n",
      "Save frame 0800-0900\n",
      "Save frame 0900-1000\n",
      "Save frame 1000-1100\n",
      "Save frame 1100-1200\n",
      "Save frame 1200-1300\n",
      "Save frame 1300-1400\n",
      "Save frame 1400-1500\n",
      "Save frame 1500-1600\n",
      "Save frame 1600-1700\n",
      "Save frame 1700-1800\n",
      "Save frame 1800-1900\n",
      "Save frame 1900-2000\n",
      "Save frame 2000-2100\n",
      "Save frame 2100-2200\n",
      "Save frame 2200-2300\n",
      "Save frame 2300-2400\n",
      "Save frame 2400-2500\n",
      "Save frame 2500-2600\n",
      "Save frame 2600-2700\n",
      "Save frame 2700-2800\n",
      "Save frame 2800-2900\n",
      "Save frame 2900-3000\n",
      "Save frame 3000-3100\n",
      "Save frame 3100-3200\n",
      "Save frame 3200-3300\n",
      "Save frame 3300-3400\n",
      "Save frame 3400-3500\n",
      "Save frame 3500-3598\n"
     ]
    }
   ],
   "source": [
    "save_folder = r'E:\\moreData\\08032020\\piv_slim\\00'\n",
    "if os.path.exists(save_folder) == False:\n",
    "    os.makedirs(save_folder)\n",
    "l = readdata(r'E:\\moreData\\08032020\\piv_imseq\\00', 'csv')\n",
    "save_frame = 100 # \n",
    "pivData = pd.read_csv(l.iloc[0].Dir)\n",
    "frame0 = int(l.iloc[0].Name.split('-')[0])\n",
    "row = len(pivData.y.drop_duplicates())\n",
    "col = len(pivData.x.drop_duplicates())\n",
    "X = np.array(pivData['x']).reshape((row, col))\n",
    "Y = np.array(pivData['y']).reshape((row, col))\n",
    "v_list = []\n",
    "for num, i in l.iterrows():       \n",
    "    pivData = pd.read_csv(i.Dir)\n",
    "    frame = int(i.Name.split('-')[0])\n",
    "    U = np.array(pivData['u']).reshape((row, col))\n",
    "    V = np.array(pivData['v']).reshape((row, col))\n",
    "    v_list.append(np.stack([U, V], axis=0))\n",
    "    if frame - 100 >= frame0 or num == len(l)-1: # every 100 frame, or reach the last row\n",
    "        print(\"Save frame {0:04d}-{1:04d}\".format(frame0, frame))        \n",
    "        v_stack = np.stack(v_list, axis=0)\n",
    "        np.save(os.path.join(save_folder, \"{0:04d}-{1:04d}\".format(frame0, frame)), v_stack)    \n",
    "        frame0 = frame\n",
    "        v_list = []\n",
    "# print(\"Save frame {0:04d}-{1:04d}\".format(frame0, frame))        \n",
    "# v_stack = np.stack(v_list, axis=0)\n",
    "# np.save(os.path.join(save_folder, \"{0:04d}-{1:04d}\".format(frame0, frame)), v_stack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Save frame 3500-3598\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frame0"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
