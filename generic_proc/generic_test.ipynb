{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test field for generic processing functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "import os\n",
    "import cv2\n",
    "from scipy import fftpack\n",
    "import time\n",
    "from nd2reader import ND2Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bpass\n",
    "\n",
    "Combining high pass and low pass filters in one function. This was originally done by directly Fourier Transform of the original image and then set 0 the undesired frequencies. Finally, the process Fourier (frequency) domain will be converted back to space domain.\n",
    "\n",
    "I remember that if the images have shape 2$^n$, the FT can be computed more efficiently. Let's do the test. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Compare FT efficiency between original image and padded image\n",
    "\n",
    "- original image shape: (682, 682)\n",
    "- padded image shape: (1024, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(682, 682)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "folder = r'E:\\moreData\\02042020\\20-1\\8-bit'\n",
    "img = io.imread(os.path.join(folder, '0000.tif'))\n",
    "dsize = (img.shape[0]//3, img.shape[1]//3)\n",
    "img_s = cv2.resize(img, dsize)\n",
    "dsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target size: 1024\n"
     ]
    }
   ],
   "source": [
    "target_size = int(2 ** (np.log(max(dsize))//np.log(2) + 1))\n",
    "print('target size: ' + str(target_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pad_width: ((171, 171), (171, 171))\n"
     ]
    }
   ],
   "source": [
    "vert_pad_before = int((target_size - dsize[0]) // 2)\n",
    "vert_pad_after = target_size - dsize[0] - vert_pad_before\n",
    "horiz_pad_before = int((target_size - dsize[1]) // 2)\n",
    "horiz_pad_after = target_size - dsize[1] - horiz_pad_before\n",
    "pad_width = ((vert_pad_before, vert_pad_after), (horiz_pad_before, horiz_pad_after))\n",
    "print('pad_width: ' + str(pad_width))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1024, 1024)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded = np.pad(img_s, pad_width)\n",
    "padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fftpack.fft2 original image: 15.00 ms\n",
      "fftpack.fft2 padded image: 32.00 ms\n",
      "np.fft.fft2 original image: 31.00 ms\n",
      "np.fft.fft2 padded image: 31.00 ms\n"
     ]
    }
   ],
   "source": [
    "tic = time.monotonic()\n",
    "im_fft_1 = fftpack.fft2(img_s)\n",
    "toc = time.monotonic()\n",
    "t1 = toc - tic\n",
    "\n",
    "tic = time.monotonic()\n",
    "im_fft_2 = fftpack.fft2(padded)\n",
    "toc = time.monotonic()\n",
    "t2 = toc - tic\n",
    "\n",
    "tic = time.monotonic()\n",
    "im_fft_3 = np.fft.fft2(img_s)\n",
    "toc = time.monotonic()\n",
    "t3 = toc - tic\n",
    "\n",
    "tic = time.monotonic()\n",
    "im_fft_4 = np.fft.fft2(padded)\n",
    "toc = time.monotonic()\n",
    "t4 = toc - tic\n",
    "\n",
    "print('fftpack.fft2 original image: ' + '{:.2f} ms'.format(t1*1000))\n",
    "print('fftpack.fft2 padded image: ' + '{:.2f} ms'.format(t2*1000))\n",
    "print('np.fft.fft2 original image: ' + '{:.2f} ms'.format(t3*1000))\n",
    "print('np.fft.fft2 padded image: ' +'{:.2f} ms'.format(t4*1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:** fftpack.fft2 has the best performance on the original image. No need to pad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Retrieve metadata from .nd2 files\n",
    "\n",
    "Although so far all the .nd2 files I have seen encodes the images in 11-bit, there is a possible occasion that the bit depth got changed and the default converter to_tif.py may run into problem. If we can retrieve the bit depth of an .nd2 image before converting to 8-bit .tif, the converter would be much more robust! [ND2Reader](https://rbnvrw.github.io/nd2reader/nd2reader.html) provides this function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with ND2Reader(r'E:\\Zhengyang\\08032020\\00.nd2') as images:\n",
    "    meta = images.metadata\n",
    "a = ''\n",
    "for kw in meta:\n",
    "    a += kw + ', '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'height, width, date, fields_of_view, frames, z_levels, z_coordinates, total_images_per_channel, channels, pixel_microns, num_frames, experiment, events, '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ND2Reader does provide some metadata, namely (height, width, date, fields_of_view, frames, z_levels, z_coordinates, total_images_per_channel, channels, pixel_microns, num_frames, experiment, events). Unfortunately, it does not provide bit depth. So for now, we still use the old convention by defaulting the bit depth to 11."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
